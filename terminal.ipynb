{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a916350-64df-4fd9-b769-26307eadbc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt install -y libcairo2-dev \\\n",
    "    texlive texlive-latex-extra texlive-fonts-extra \\\n",
    "    texlive-latex-recommended texlive-science \\\n",
    "    tipa libpango1.0-dev\n",
    "!pip install manim\n",
    "!pip install IPython==8.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c847ff-8fb4-423c-8d0b-83ae218dac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c266e135-b7f2-4abb-bc9f-cd3847a0081f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-04 23:08:28.035449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using device: cpu\n",
      "NOTE: If you have a GPU, consider using it for training.\n",
      "On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\n",
      "On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "No model to preload, starting from scratch\n",
      "Processing Epoch 00:   5%|▍       | 61/1263 [00:31<10:29,  1.91it/s, loss=7.058]^C\n",
      "Processing Epoch 00:   5%|▍       | 61/1263 [00:32<10:34,  1.89it/s, loss=7.058]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/pipeline.py\", line 181, in <module>\n",
      "    train_model(config)\n",
      "  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/pipeline.py\", line 135, in train_model\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02334c43-6847-4804-b503-2ca0e10698ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "#from translate import translate\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bddc5-99dc-4d27-b95a-44bc215841bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
