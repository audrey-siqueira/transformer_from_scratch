{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a916350-64df-4fd9-b769-26307eadbc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt install -y libcairo2-dev \\\n",
    "    texlive texlive-latex-extra texlive-fonts-extra \\\n",
    "    texlive-latex-recommended texlive-science \\\n",
    "    tipa libpango1.0-dev\n",
    "!pip install manim\n",
    "!pip install IPython==8.21.0\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c266e135-b7f2-4abb-bc9f-cd3847a0081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/train.py\", line 23, in <module>\n",
      "    import torchmetrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/__init__.py\", line 14, in <module>\n",
      "    from torchmetrics import functional  # noqa: E402\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/__init__.py\", line 14, in <module>\n",
      "    from torchmetrics.functional.audio._deprecated import _permutation_invariant_training as permutation_invariant_training\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/audio/__init__.py\", line 14, in <module>\n",
      "    from torchmetrics.functional.audio.pit import permutation_invariant_training, pit_permutate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/audio/pit.py\", line 23, in <module>\n",
      "    from torchmetrics.utilities import rank_zero_warn\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/utilities/__init__.py\", line 14, in <module>\n",
      "    from torchmetrics.utilities.checks import check_forward_full_state_property\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/utilities/checks.py\", line 25, in <module>\n",
      "    from torchmetrics.metric import Metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/metric.py\", line 30, in <module>\n",
      "    from torchmetrics.utilities.data import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/utilities/data.py\", line 22, in <module>\n",
      "    from torchmetrics.utilities.imports import _TORCH_GREATER_EQUAL_1_12, _XLA_AVAILABLE\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchmetrics/utilities/imports.py\", line 41, in <module>\n",
      "    _TORCHVISION_GREATER_EQUAL_0_8: Optional[bool] = compare_version(\"torchvision\", operator.ge, \"0.8.0\")\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lightning_utilities/core/imports.py\", line 78, in compare_version\n",
      "    pkg = importlib.import_module(package)\n",
      "  File \"/opt/conda/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import datasets, io, models, ops, transforms, utils\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
      "    from . import detection, optical_flow, quantization, segmentation, video\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
      "    from .faster_rcnn import *\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
      "    from .anchor_utils import AnchorGenerator\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
      "    class AnchorGenerator(nn.Module):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
      "    device: torch.device = torch.device(\"cpu\"),\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n",
      "Using device: cuda\n",
      "Device name: Tesla V100-SXM2-16GB\n",
      "Device memory: 15.7657470703125 GB\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 1000     /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "Max length of source sentence: 204\n",
      "Max length of target sentence: 196\n",
      "1606\n",
      "1929\n",
      "No model to preload, starting from scratch\n",
      "Processing Epoch 00:  89%|████████▉ | 16/18 [00:00<00:00, 32.26it/s, loss=7.621]Ativado save_debug para: encoder.layers.0.self_attention_block\n",
      "Ativado save_debug para: encoder.layers.0.feed_forward_block\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.0\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.0.norm\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.1\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.1.norm\n",
      "Ativado save_debug para: encoder.norm\n",
      "Ativado save_debug para: decoder.layers.0.self_attention_block\n",
      "Ativado save_debug para: decoder.layers.0.cross_attention_block\n",
      "Ativado save_debug para: decoder.layers.0.feed_forward_block\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.0\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.0.norm\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.1\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.1.norm\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.2\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.2.norm\n",
      "Ativado save_debug para: decoder.norm\n",
      "Ativado save_debug para: src_embed\n",
      "Ativado save_debug para: tgt_embed\n",
      "Ativado save_debug para: src_pos\n",
      "Ativado save_debug para: tgt_pos\n",
      "Ativado save_debug para: projection_layer\n",
      "Debug info saved to vars/InputEmbedding_0.json\n",
      "Debug info saved to vars/PositionalEncoding_0.json\n",
      "Debug info saved to vars/LayerNormalization_0.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_0.json\n",
      "Debug info saved to vars/ResidualConnection_0.json\n",
      "Debug info saved to vars/LayerNormalization_1.json\n",
      "Debug info saved to vars/FeedForwardBlock_0.json\n",
      "Debug info saved to vars/ResidualConnection_1.json\n",
      "Debug info saved to vars/LayerNormalization_2.json\n",
      "Debug info saved to vars/InputEmbedding_1.json\n",
      "Debug info saved to vars/PositionalEncoding_1.json\n",
      "Debug info saved to vars/LayerNormalization_3.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_1.json\n",
      "Debug info saved to vars/ResidualConnection_2.json\n",
      "Debug info saved to vars/LayerNormalization_4.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_2.json\n",
      "Debug info saved to vars/ResidualConnection_3.json\n",
      "Debug info saved to vars/LayerNormalization_5.json\n",
      "Debug info saved to vars/FeedForwardBlock_1.json\n",
      "Debug info saved to vars/ResidualConnection_4.json\n",
      "Debug info saved to vars/LayerNormalization_6.json\n",
      "Debug info saved to vars/ProjectionLayer_0.json\n",
      "Processing Epoch 00: 100%|██████████| 18/18 [00:01<00:00, 15.18it/s, loss=7.324]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/train.py\", line 299, in <module>\n",
      "    train_model(config)\n",
      "  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/train.py\", line 284, in train_model\n",
      "    run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
      "  File \"/mnt/custom-file-systems/efs/fs-0a0b857e0cd732c6d_fsap-0c621f83c851d0d4c/pytorch-transformer/train.py\", line 91, in run_validation\n",
      "    model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Numpy is not available\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02334c43-6847-4804-b503-2ca0e10698ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "#from translate import translate\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
