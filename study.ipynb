{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a916350-64df-4fd9-b769-26307eadbc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt install -y libcairo2-dev \\\n",
    "    texlive texlive-latex-extra texlive-fonts-extra \\\n",
    "    texlive-latex-recommended texlive-science \\\n",
    "    tipa libpango1.0-dev\n",
    "!pip install manim\n",
    "!pip install IPython==8.21.0\n",
    "\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c266e135-b7f2-4abb-bc9f-cd3847a0081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-14 00:36:36.177427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using device: cpu\n",
      "NOTE: If you have a GPU, consider using it for training.\n",
      "      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\n",
      "      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
      "Max length of source sentence: 204\n",
      "Max length of target sentence: 196\n",
      "1606\n",
      "1929\n",
      "No model to preload, starting from scratch\n",
      "Processing Epoch 00:  75%|██████▊  | 12/16 [00:00<00:00, 112.81it/s, loss=7.711]Ativado save_debug para: encoder.layers.0.self_attention_block\n",
      "Ativado save_debug para: encoder.layers.0.feed_forward_block\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.0\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.0.norm\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.1\n",
      "Ativado save_debug para: encoder.layers.0.residual_connections.1.norm\n",
      "Ativado save_debug para: encoder.norm\n",
      "Ativado save_debug para: decoder.layers.0.self_attention_block\n",
      "Ativado save_debug para: decoder.layers.0.cross_attention_block\n",
      "Ativado save_debug para: decoder.layers.0.feed_forward_block\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.0\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.0.norm\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.1\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.1.norm\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.2\n",
      "Ativado save_debug para: decoder.layers.0.residual_connections.2.norm\n",
      "Ativado save_debug para: decoder.norm\n",
      "Ativado save_debug para: src_embed\n",
      "Ativado save_debug para: tgt_embed\n",
      "Ativado save_debug para: src_pos\n",
      "Ativado save_debug para: tgt_pos\n",
      "Ativado save_debug para: projection_layer\n",
      "Debug info saved to vars/InputEmbedding_0.json\n",
      "Debug info saved to vars/PositionalEncoding_0.json\n",
      "Debug info saved to vars/LayerNormalization_0.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_0.json\n",
      "Debug info saved to vars/ResidualConnection_0.json\n",
      "Debug info saved to vars/LayerNormalization_1.json\n",
      "Debug info saved to vars/FeedForwardBlock_0.json\n",
      "Debug info saved to vars/ResidualConnection_1.json\n",
      "Debug info saved to vars/LayerNormalization_2.json\n",
      "Debug info saved to vars/InputEmbedding_1.json\n",
      "Debug info saved to vars/PositionalEncoding_1.json\n",
      "Debug info saved to vars/LayerNormalization_3.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_1.json\n",
      "Debug info saved to vars/ResidualConnection_2.json\n",
      "Debug info saved to vars/LayerNormalization_4.json\n",
      "Debug info saved to vars/MultiHeadAttentionBlock_2.json\n",
      "Debug info saved to vars/ResidualConnection_3.json\n",
      "Debug info saved to vars/LayerNormalization_5.json\n",
      "Debug info saved to vars/FeedForwardBlock_1.json\n",
      "Debug info saved to vars/ResidualConnection_4.json\n",
      "Debug info saved to vars/LayerNormalization_6.json\n",
      "Debug info saved to vars/ProjectionLayer_0.json\n",
      "Processing Epoch 00: 100%|██████████| 16/16 [00:00<00:00, 28.34it/s, loss=7.481]\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I--'\n",
      "    TARGET: Eu--\"\n",
      " PREDICTED: aquilo chama por era\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: CHORUS\n",
      "    TARGET: REFRÃO\n",
      " PREDICTED: aquilo chama era era\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02334c43-6847-4804-b503-2ca0e10698ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 00:37:37.170065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Max length of source sentence: 204\n",
      "Max length of target sentence: 196\n",
      "1606\n",
      "1929\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Well!\n",
      "    TARGET: \"Bem!\n",
      " PREDICTED: aquilo chama por era\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "#from translate import translate\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295752a-d012-4725-9e76-a0d527df9d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
